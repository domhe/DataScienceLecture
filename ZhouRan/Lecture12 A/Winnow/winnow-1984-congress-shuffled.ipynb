{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 10</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 8 April 2019</div>\n",
    "\n",
    "# Review: Regression Analysis\n",
    "\n",
    "You had your humble beginnings in data science and machine learning in INFO 6105, with a professor that loves bikes :-) I need to make sure you know the *basics* before you move on to a Coop or a more complicated class, so that employers and professors can be impressed by *how much you know*. So let's do a bit of review.\n",
    "\n",
    "**Regression analysis** is a **statistical process** for estimating relationships among variables.\n",
    "\n",
    "It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a **dependent variable** and one or more **independent variables** (or 'predictors').\n",
    "\n",
    "More specifically, regression analysis helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed\n",
    "Regression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of machine learning.\n",
    "\n",
    "**Linear Regression** is a simple approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variable (independent variable) x where data are modeled using linear predictor functions. \n",
    "Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as with Bayesian modeling where we try to maximize the probability of observing the data.\n",
    "\n",
    "The decision as to which variable in a data set is modeled as the dependent variable and which are modeled as the independent variables may be based on a presumption that the value of one of the variables is caused by, or directly influenced by the other variables. That decision is the most important one in regression analysis. A decision forest can help you determine these variables, using information theoretic metrics like **Information Gain**.\n",
    "\n",
    "There are two kinds of regression analyses: **auto-encoding** and **discriminative**. In the former, we learn to model the entire datase. In the latter we attempt to classify data in bins. In the picture below, we classify data in two color bins by shaping the right **decision boundary**. In the regression model, we shape parameters using a probabilistic framework like PyMC3. In Machine Learning, we adjust the weights between the neurons to get the right decision boundary.\n",
    "\n",
    "In the beginning of the semester, I told you that Machine Learning is a *geometric problem*. Now you see why. On Wednesday, you'll understand this *even better*. And you're never going to be scared by a machine again :-)\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/decision-boundary.png width = 800 />\n",
    "</center>\n",
    "\n",
    "If the neural transfer function is linear, the ANN can only draw straight  decision boundaries, even if there are many layers of units. And so it might not work in general. It is the **non-linearity** of the neural transfer function that adds modeling power to your ANN. And yet, we can still model with linear decsion boundaries, as we will see today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The winnow algorithm\n",
    "\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/winnow.png\" width=400 />\n",
    "</center>\n",
    "\n",
    "*Winnowing* means **removing unwanted items**. Its purpose as an algorthm is to train a binary classifier based on binary features, using a *linear* decision boundary.\n",
    "\n",
    "In other words, the goal is to predict one of two states, using a collection of features which are all binary.\n",
    "\n",
    "Our networks so far have been equal-weighted. But with artifical neural networks, are edges acquire weights between nodes. It's similar to the facebook friends graph. Our facebook friends are simiarly weighted. But in reality, we like some friends a lot more than others!\n",
    "\n",
    "The prediction model assigns weights to each feature. To predict the state of an observation, it checks all the features that are “active” (true, or detected in an observation) and sums up the weights assigned to these features. If the total is *above* a certain threshold, the result is true, otherwise it’s false. \n",
    "\n",
    "So we create a network (I know you can do this very well now), and initialize weights $w_1 = w_2 = \\cdots = w_n = 1$.\n",
    "\n",
    "Then we iterate on each observation consisting of a vector of dimension $n$: $ = [x_1, x_2, \\cdots, x_n]$.\n",
    "\n",
    "We predict (for each iteration **epoch**): Output is 1 if *{some condition}*. Output is 0 otherwise.\n",
    "\n",
    "Then, we get the **true** (binary) label corresponding to that observation, and we update the weights **only if we make a mistake**:\n",
    "- **False-positive** error (we predict 0 wheras the label is really 1): Then for each $x_i == 1$, we set $w_i = 2*w_i$.\n",
    "- **False-negative** error (we predict 1 wheras the label is really 0): Then for each $x_i == 1$, we set $wi = wi/2$.\n",
    "\n",
    "Here is the *english* of the math above:\n",
    "If our network predicts true but should predict false, it is **over-shooting**, so weights that were used in the prediction (i.e. the weights attached to active features) should be reduced.\n",
    "Conversely, if the prediction is false but the correct result should be true, the active features are not used enough to reach the threshold, so weights should be bumped up.\n",
    "\n",
    "Our goal is to minimze the number of mistakes. When we're down to the minimum we can achieve, we say we have **converged**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dataset: 1984 Congress\n",
    "\n",
    "The Machine learning repository at the University of California, Irvine, has some great data sets. [Here](https://archive.ics.uci.edu/ml/datasets/congressional+voting+records) are the congressional voting records of the House of Representatives for a select set of bills in the 1984 Congress.\n",
    "\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/congress.jpg\" width=600 />\n",
    "</center>\n",
    "\n",
    "Our goal is to predict the political party, Democrat or Republican, of a member of the U.S. House of Representatives, based on the Representative’s votes on 16 different bills. An example of a bill is \"Should we drill for oil in Alaskan National Parks\"?\n",
    "\n",
    "The House of Representatives has 435 members. A well-known benchmark data set contains 435 items stored in a simple text [file](https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/).\n",
    "\n",
    "You told me last week that you wanted to do some coding. So this is the **simplest** possible artifical neural network I can come up with that has a chance at learning a dataset/ It's so simple that it does *not* have a non-linear transfer function in in its neuron: it lets the *entire* signal pass through! Do you think that can work as an artificial brain? \n",
    "\n",
    "Let's see.\n",
    "\n",
    "We should strive to ensure that our accuracy on the test data is 70% or above (anything approaching 50% is junk: just a guess!). Rerun your training (which shuffles the data), or change your random number generator seed maybe? Add another layer? Those could be hyperparameters?\n",
    "\n",
    "### These are the questions we want to be able to answer:\n",
    "\n",
    "Based on the Representatives' voting records on those bills, and knowledge of party affiliation (label), can we guess if a person is a republican or democrat based on how they would vote (`yes` or `nay`) on these bills? If a person voted all `nays` or all `yays` on all bills, would they be democrats or republicans based on how congressmen vote on these bills?\n",
    "\n",
    "Is there a bill that is more important than others in determining whether a congressman is republican or democrat? Can you figure this out just by looking at the weights of your winnow network?\n",
    "\n",
    "Finally, compare the performance of your winnow versus the performance of a random forest algorithm.\n",
    "\n",
    "### winnow algorithm:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialize weights\n",
    "loop until done\n",
    "  for each training item\n",
    "    compute Y\n",
    "    if correct do nothing\n",
    "    else if incorrect\n",
    "      if computed Y is too large\n",
    "        divide all relevant weights by 2.0\n",
    "      else if computed Y is too small\n",
    "        multiply all relevant weights by 2.0\n",
    "  end for\n",
    "end loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crazy professor\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/crazy.jpg\" width=400 />\n",
    "</center>\n",
    "\n",
    "Oh no! Crazy professor tried to create a new class to add the Winnow algorithm and he edited the .ipynb files manually, and he completely **$&!&~~wed up the cells**! Based on what I told you above, can you reconstruct the cells so that it works?\n",
    "```(python)\n",
    "class Winnow:\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9b4a0cba76ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction accuracy on training data = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainAcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction accuracy on test data = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestAcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "trainAcc = w.Accuracy(trainData)\n",
    "testAcc = w.Accuracy(testData)\n",
    "\n",
    "print(\"Prediction accuracy on training data = \" + str(trainAcc))\n",
    "print(\"Prediction accuracy on test data = \" + str(testAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model weights are:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ShowVector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dcd35f464c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final model weights are:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mShowVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ShowVector' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Final model weights are:\")\n",
    "ShowVector(weights, 4, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting party of Representative with all 'yes' votes: \", end='')\n",
    "yays = [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ]\n",
    "predicted = w.ComputeY(yays)\n",
    "if predicted == 0:\n",
    "    print(\"democrat\")\n",
    "else:\n",
    "    print(\"republican\")\n",
    "\n",
    "print(\"Predicting party of Representative with all 'no' votes: \", end='')\n",
    "nays = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "predicted2 = w.ComputeY(nays)\n",
    "if predicted2 == 0:\n",
    "    print(\"democrat\")\n",
    "else:\n",
    "    print(\"republican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Encoding 'n' and '?' = 0, 'y' = 1, 'democrat' = 0, 'republican' = 1\")\n",
    "print(\"Moving political party to last column\")\n",
    "print(\"First few rows of training data are:\")\n",
    "ShowMatrix(trainData, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of all data are:\n",
      "[00]   0 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 \n",
      "[01]   0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 \n",
      "[02]   0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 \n",
      "[03]   0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 \n",
      "[99]   0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into 80% train and 20% test matrices\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of testing data are:\n",
      "[00]   0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 \n",
      "[01]   1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 \n",
      "[02]   0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 \n",
      "[99]   0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training using Winnow algorithm\n",
      "Training complete\n",
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on training data = 0.99\n",
      "Prediction accuracy on test data = 0.61\n"
     ]
    }
   ],
   "source": [
    "trainAcc = w.Accuracy(trainData)\n",
    "testAcc = w.Accuracy(testData)\n",
    "\n",
    "print(\"Prediction accuracy on training data = \" + str(trainAcc))\n",
    "print(\"Prediction accuracy on test data = \" + str(testAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First few lines of all data are:\")\n",
    "ShowMatrix(data, 0, 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
