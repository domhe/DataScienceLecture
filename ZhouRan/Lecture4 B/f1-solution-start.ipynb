{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Sci Engineering Methods and Tools, Week 4 Lecture 1</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 4 February 2019</div>\n",
    "\n",
    "We correct your data science homework involving Formula 1 driving. \n",
    "\n",
    "Let's use the following probability function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def p(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...} with outcomes where predicate(element) is true;\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...} with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/f1races.png\" width=800 />\n",
    "</center>\n",
    "\n",
    "Question 1.1 (20 points) There are two F1 races coming up: The Russian Grand Prix this weekend and the Japanese Grand Prix the weekend after. The 2018 driver standings are given [here](https://www.formula1.com/en/results.html/2018/drivers.html). Given these standings (please do not use team standings given on the same Web site, use driver standings), what is the Probability Distribution for each F1 driver to win the Russian Grand Prix? What is the Probability Distribution for each F1 driver to win *both* the Russian and Japanese Grand Prix? What is the probability for Ferrari to win both races? What is the probability for Ferrari to win at least one race? Note that Ferrari, and each other racing team, has two drivers per race.\n",
    "\n",
    "Question 1.2 (30 points) If Ferrari wins the first race, what is the probability that Ferrari wins the next one? If Ferrari wins at least one of these two races, what is the probability Ferrari wins both races? How about Mercedes, Red Bull, and Williams?\n",
    "\n",
    "Question 1.3 (50 points) Ferrari wins one of these two races on a rainy day. What is the probability Ferrari wins both races, assuming races can be held on either rainy, sunny, cloudy, snowy or foggy days? Assume that rain, sun, clouds, snow, and fog are the only possible weather conditions on race tracks.\n",
    "\n",
    "You need to provide *proof* for your answers. `I think it's one in a million because Ferrari sucks` is not a good answer. Leverage the counting framework in this workbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put the standings here, so you don't have to refer to the Web site every time. Leave the cell unformatted.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use `RGP` to denote the Probability Distribution given by F1 driver wins. Write driver initials as keys and driver wins as values in a dictionary that you pass to our function `ProbDist`..\n",
    "\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGP = ProbDist(\n",
    "    LH = 281,\n",
    "    SV = 241,\n",
    "    KR = 174,\n",
    "    VB = 171,\n",
    "    MV = 148,\n",
    "    DR = 126,\n",
    "    NH = 53,\n",
    "    FA = 50,\n",
    "    KM = 49,\n",
    "    SP = 46,\n",
    "    EO = 45,\n",
    "    CS = 38,\n",
    "    PG = 28,\n",
    "    RG = 27,\n",
    "    CL = 15,\n",
    "    SD = 8,\n",
    "    LS = 6,\n",
    "    ME = 6,\n",
    "    BH = 2,\n",
    "    SS = 1)\n",
    "RGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of two successive wins is just the square of each single win probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x ** 2.0\n",
    "RJGP = {k: f(v) for k, v in RGP.items()}\n",
    "RJGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also compute this in a different way. You could leverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint(A, B, sep=' '):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "RJGP2 = joint(RGP, RGP, ' ')\n",
    "import random\n",
    "winners_rnd = random.sample(list(RJGP2), 10)\n",
    "print(winners_rnd)\n",
    "probs_rnd = [RJGP2[k] for k in winners_rnd]\n",
    "winners_n_probs_rnd = ...\n",
    "print('\\n'.join([str(outcome) for outcome in winners_n_probs_rnd]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the sum of all probabilities is 1:\n",
    "```python\n",
    "all_probs = [RJGP2[k] for k in RJGP2]\n",
    "sum(all_probs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([outcome for outcome in RJGP2 ])\n",
    "#print(list(zip(RJGP2.keys(), RJGP2.values())))\n",
    "winners = RJGP2.keys()\n",
    "probs = RJGP2.values()\n",
    "double_winners = {x for x in winners if x[0] == x[3] and x[1] == x[4]}\n",
    "#print(double_winners)\n",
    "probs = [RJGP2[k] for k in double_winners]\n",
    "double_winners_n_probs = ...\n",
    "print('\\n'.join([str(outcome) for outcome in double_winners_n_probs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. which matches our previous result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since The Ferrari drivers are Kimmi Raikkonen (KR) and Sebastien Vettel (SV), the probability of Ferrari winning *both* races are represented by keys KR SV, SV KR, KR KR, and SV SV. And so the probability of Ferrari winning *both* races is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = RJGP2.keys()\n",
    "probs = RJGP2.values()\n",
    "print(len(winners))\n",
    "#Ferrari_wins_2 = {x for x in winners if x in ('KR SV', 'SV KR', 'KR KR', 'SV SV')}\n",
    "Ferrari_wins_2 = {...}\n",
    "#print(Ferrari_wins_2)\n",
    "Ferrari_probs_2 = [RJGP2[k] for k in Ferrari_wins_2]\n",
    "#Ferrari_wins_2_n_probs = list(zip(Ferrari_wins_2, Ferrari_probs_2))\n",
    "#print('\\n'.join([str(outcome) for outcome in Ferrari_wins_2_n_probs]))\n",
    "Ferrari_wins_2_prob = sum(Ferrari_probs_2)\n",
    "print('Probability of Ferrari drivers winning both races is: ' + str(Ferrari_wins_2_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the probability of Ferrari winning *one of these races* is any win combination that includes one of the Ferrari drivers as keys. Note that this includes *both* Ferrari drivers winning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = RJGP2.keys()\n",
    "print(len(winners))\n",
    "#Ferrari_wins_1 = {x for x in winners if 'KR ' in x or ' KR' in x or 'SV ' in x or ' SV' in x}\n",
    "Ferrari_wins_1 = {...}\n",
    "print('all possible combinations for one Ferrari win: ')\n",
    "print(sorted(Ferrari_wins_1))\n",
    "#print('\\n'.join(sorted(Ferrari_wins_1)))\n",
    "print(len(Ferrari_wins_1))\n",
    "Ferrari_probs_1 = [RJGP2[k] for k in Ferrari_wins_1]\n",
    "#print(Ferrari_probs_1)\n",
    "#print(len(Ferrari_probs_1))\n",
    "#Ferrari_wins_1_probs = list(zip(Ferrari_wins_1, Ferrari_probs_1))\n",
    "#print('\\n'.join([str(outcome) for outcome in Ferrari_wins_1_n_probs]))\n",
    "Ferrari_wins_1_prob = sum(Ferrari_probs_1)\n",
    "print('Probability of Ferrari drivers winning one of these races is: ' + str(Ferrari_wins_1_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiat.. That seems strange... Sounds like a good bet for Ferrari.. \n",
    "<center>\n",
    "    <img src=\"ipynb.images/scrat.png\" width=200 />\n",
    "</center>\n",
    "\n",
    "Let's do some debugging. You should always do this when you get strange results in Data Science. Slow down, and retrace your steps in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_dbg(A, B, sep=' '):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + '(' + \"{0:.4f}\".format(A[a]) + ')' + sep + b + '(' + \"{0:.4f}\".format(B[b]) + ')' + sep \n",
    "                     + \"{0:.4f}\".format(A[a] * B[b]): A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recompute *carefully*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RJGP3 = joint_dbg(RGP, RGP)\n",
    "winners = RJGP3.keys()\n",
    "print('Possible win combinations: ' + str(len(winners)))\n",
    "\n",
    "#print('Mercedes:')\n",
    "Mercedes_wins_1 = [x for x in winners if x.count('LH') + x.count('SV') ...]\n",
    "#print(Mercedes_wins_1)\n",
    "Mercedes_wins_1_probs = [float(x[22:]) for x in Mercedes_wins_1]\n",
    "#print(Mercedes_wins_1_probs)\n",
    "print('Probability of at least one Mercedes victory: ' + str(sum(Mercedes_wins_1_probs)))\n",
    "#print('---------')\n",
    "\n",
    "#print('Ferrari:')\n",
    "Ferrari_wins_1 = [x for x in winners if x.count('SV') + x.count('KR') ...]\n",
    "#print(Ferrari_wins_1)\n",
    "Ferrari_wins_1_probs = [float(x[22:]) for x in Ferrari_wins_1]\n",
    "#print(Ferrari_wins_1_probs)\n",
    "print('Probability of at least one Ferrari victory: ' + str(sum(Ferrari_wins_1_probs)))\n",
    "#print('---------')\n",
    "\n",
    "#print('Red Bull:')\n",
    "RedBull_wins_1 = [x for x in winners if x.count('MV') + x.count('DR') ...]\n",
    "#print(RedBull_wins_1)\n",
    "RedBull_wins_1_probs = [float(x[22:]) for x in RedBull_wins_1]\n",
    "#print(RedBull_wins_1_probs)\n",
    "print('Probability of at least one Red Bull victory: ' + str(sum(RedBull_wins_1_probs)))\n",
    "#print('---------')\n",
    "      \n",
    "#print('Williams:')\n",
    "Williams_wins_1 = [x for x in winners if x.count('LS') + x.count('SS') ...]\n",
    "#print(Williams_wins_1)\n",
    "Williams_wins_1_probs = [float(x[22:]) for x in Williams_wins_1]\n",
    "#print(Williams_wins_1_probs)\n",
    "print('Probability of at least one Williams victory: ' + str(sum(Williams_wins_1_probs)))\n",
    "#print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do the probabilities *not add up to 1*?!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had computed the probability of one Ferrari win by squaring the probability of a 'KR' or 'SV' win, you would be making a *mistake*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ferrari_win = {RGP[k] for k in ('KR', 'SV')}\n",
    "print(Ferrari_win)\n",
    "print('one win: ' + str(sum(Ferrari_win)))\n",
    "print('two wins: ' + str(sum(Ferrari_win) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so the probability of Mercedes or Ferrari drivers winning at least one of these races is much higher than the probability of winning one race. See the difference that *at least* makes? The probability of winning both races is much easier to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "If Ferrari wins one of these races (assume that is given as evidence), what is the probability that Ferrari wins both of them? If Ferrari wins at least one of these two races (assume that is given as evidence), what is the probability Ferrari wins both races? How about Mercedes-McLaren?\n",
    "\n",
    "RJGP has 400 possible outcomes. This is a random sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(RJGP2))\n",
    "import random\n",
    "winners = random.sample(list(RJGP2), 10)\n",
    "probs = [RJGP2[k] for k in winners]\n",
    "winners_n_probs = list(zip(winners, probs))\n",
    "print('\\n'.join([str(outcome) for outcome in winners_n_probs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Ferrari wins one race, then the probability that Ferrari also wins the next one is just the probability of Ferrari winning one race, which is 27%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this from a different perspective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Ferrari wins the first race (Russian Grand Prix), what is the probability Ferrari wins the next one (Japanese Grand Prix)? If Ferrari wins at least one of these races, what is the probability Ferrari wins both?\n",
    "\n",
    "Let's define predicates for Ferrari winning the next race `next_ferrari_win_p`, Ferrari winning at least one race (not only one race!) `one_ferrari_win_p`, and Ferrari winning 2 races `two_ferrari_wins_p`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_ferrari_win_p(outcome): ...\n",
    "def one_ferrari_win_p(outcome): return outcome.count('KR') + outcome.count('SV') ...\n",
    "def two_ferrari_wins_p(outcome): return outcome.count('KR') + outcome.count('SV') ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a new joint probability distribution that takes in a predicate as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_p(A, B, pred, sep=' '):\n",
    "    \"\"\"The joint distribution of two independent probability distributions, with a condition \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B\n",
    "                    ...})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability Ferrari wins the Japanese Grand Prix given that it won the Russian Grand Prix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ferrari_win = joint_p(RGP, RGP, next_ferrari_win_p, ' ')\n",
    "len(next_ferrari_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(two_ferrari_wins, next_ferrari_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the probability that Ferrari wins both races given that it won *at least one of them*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_ferrari_win = joint_p(RGP, RGP, one_ferrari_win_p, ' ')\n",
    "len(one_ferrari_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(two_ferrari_wins, one_ferrari_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the answer is tougher. Some people may think the answer should be 27%. Can we justify the answer 16%? \n",
    "\n",
    "A win on the Russian Grand Prix does not really affect the probabily of winning the next race, so it's just the probability for Ferrari of winning *a* race.\n",
    "\n",
    "But there are more possibilities for `at least one Ferrari win` than `a Ferrari win for the Japanese Grand Prix`. And so our sample space is different. When we add up favorable outcomes, the total probability is smaller. \n",
    "\n",
    "Intuitively, if I tell you the Patriots won the AFC Championship game against the Chiefs two weekends ago, what's the probability they will win the Superbowl against the Rams, too? You will say, \"oh, good chance, good team\"! But if i tell you that over this weekend *and* next, the Patriots are going to win at least one game, and you know they already won one game, you will probably say, \"oh, that means they will loose the next one\", or at least you won't be as confident about the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Ferrari wins one of these races on a rainy day (Ferrari has great Pirelli tires). What is the probability Ferrari wins both races, assuming races can be held on either rainy, sunny, cloudy, snowy or foggy days? Assume that rain, sun, clouds, snow, and fog are the only possible weather conditions on race tracks.\n",
    " \n",
    "One Ferrari win is on a cloudy day. What's the probability both races are wins for Ferrari?\n",
    "\n",
    "Whaaaaat? Why do we care that Ferrari wins on a cloudy day? Well, we do, because that is *extra* information. For example, it may tell us that Ferrari has great tires, so any time it rains, Ferrari is a proven winner on rainy tracks. It allows us to computer a *posterior* probability to update a *prior*, given new evidence. That is the foundation of bayesian statistics and Bayesian Machine Learning, which we'll cover this week.\n",
    " \n",
    "We have a *non-uniform* probability distribution for racers, and a *uniform* probability distribution for weather conditions. Let's derive the joint distribution for one race, and the joint distribution over two races.\n",
    "\n",
    "A Uniform distribution is just like a Probability distribution, except that all the values (probabilities) are the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Uniform(outcomes): return ProbDist({event: 1 for event in outcomes})\n",
    "F1_1_conditions  = ...\n",
    "F1_2_conditions = joint(F1_1_conditions, F1_1_conditions)\n",
    "len(F1_2_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10,000 different combinations of wins over two races, with weather conditions! Let's sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(list(F1_2_conditions), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, one possibility is Lewis Hamilton winning the first race on a foggy day, and Fernando Alonso winning the second race on a rainy day: {LHf FAr}.\n",
    "\n",
    "We determine below the probability of *at least* one Ferrari win over two races, both where we keep track of weather conditions and where we don't, is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_ferrari_win_p(outcome): return outcome.count('KR') + outcome.count('SV') ...\n",
    "p(one_ferrari_win_p, RJGP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"LHf FAr\".count('LH') + \"LHf FAr\".count('FA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(one_ferrari_win_p, F1_2_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine below that the probability of two Ferrari wins, both where we keep track of weather conditions and where we don't, is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(two_ferrari_wins_p, RJGP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(two_ferrari_wins_p, F1_2_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the probability of one Ferrari win and of two Ferrari wins is independent of weather conditions.\n",
    "\n",
    "Ok, now we're reassured that we are not crazy, and the professor is not part of some alien conspiracy to make us *think we're crazy*.\n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/Scrat_Ice_Age.png\" width=200 />\n",
    "</center>\n",
    "\n",
    "Now, we have to figure the probability of two Ferrari wins given the evidence of one Ferrari win on a cloudy day. Hmmmmmm.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's' define a predicate for the event of a Ferrari win on a rainy day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_least_one_Ferrari_win_on_a_rainy_day(outcome): return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_2_conditions_at_least_one_Ferrari_win_on_a_rainy_day = (\n",
    "    joint_p(...)\n",
    ")\n",
    "len(F1_2_conditions_at_least_one_Ferrari_win_on_a_rainy_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 10,000 possibilities, we have 396 favorable outcomes. And so the probability for two Ferrari wins over two races given that Ferrari won one of them on a cloudy day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_ferrari_wins_p(outcome): return outcome.count('KR') + outcome.count('SV') ...\n",
    "p(two_ferrari_wins_p, F1_2_conditions_at_least_one_Ferrari_win_on_a_rainy_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of two Ferrari wins when we know that Ferrari wins at least one race on a rainy day is 25%, which is much higher than the probability of two Ferrari wins (7%), and lower than the probability of at least one Ferrari win (47%). That's the value of extra information: It produces a different posterior!\n",
    "\n",
    "Wow, Bayesian statistics looks like great stuff, like maybe I can use to play at the new Boston [Casino](https://encorebostonharbor.com/), but what if the professor is just trying to seduce us with complicated programming?\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/seduce.png\" width=300 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some debugging. Let's display results as a 2D grid of outcomes. A cell will be colored white if Ferrari does not win two races, yellow if Ferrari wins two races but not with a least one win on a cloudy day, and green if Ferrari wins two races with at leat one win on a cloudy day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce the amount of data to being our debugging, to just Ferrari, Renault, and Williams. You always debug with less data! And I picked these teams because they cover the range of wins: a lot, medium, very few. I'll also reduce weather to (r)ain, and (s)un."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Uniform(outcomes): return ProbDist({event: 1 for event in outcomes})\n",
    "\n",
    "def joint(A, B, sep=' '):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "def next_ferrari_win_p(outcome): return outcome.count(' KR') + outcome.count(' SV') == 1\n",
    "def one_ferrari_win_p(outcome): return outcome.count('KR') + outcome.count('SV') >= 1\n",
    "def two_ferrari_wins_p(outcome): return outcome.count('KR') + outcome.count('SV') == 2\n",
    "\n",
    "def at_least_one_Ferrari_win_on_a_rainy_day(outcome): return 'KRr' in outcome or 'SVr' in outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning one race. Ferrari is SV and KR\n",
    "RGPr = ProbDist(\n",
    "    SV = 241,\n",
    "    KR = 171,\n",
    "    NH = 53,\n",
    "    CS = 38,\n",
    "    LS = 6,\n",
    "    SS = 1)\n",
    "RGPr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning a race on a specific weather condition\n",
    "RGPrw  = joint(RGPr, ..., '') #care about the weather\n",
    "RGPrw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning two races on specific weather conditions\n",
    "RJGPrw  = joint(RGPrw, RGPrw)\n",
    "len(RJGPrw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, I can work with 12 x 12 data points, they won't fry my kernel. What do they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(list(RJGPrw), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some plotting. Machine learning is all about *geometry* (specifically, building outcome manifolds in state space that represent the surface joining all possible outcomes). That is why we debug everything with pictures.\n",
    "\n",
    "Let's plot all possible outcomes of our discrete probability distribution on a grid, and color cells in green and yellow depending on two respective predicates. If one is true, color the cell any color (yellow or green), if the other is true *as well*, color the cell green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def Pgrid(event, condition, dist):\n",
    "    def first_half(s): return s[:len(s)//2]\n",
    "    firsts = sorted(set(map(first_half, dist)))\n",
    "    return HTML('<table>' +\n",
    "                cat(row(first, event, dist, condition) for first in firsts) +\n",
    "                '</table>')\n",
    "\n",
    "def row(first, event, dist, condition):\n",
    "    \"Display a row where the first race result is paired with each of the possible second race results.\"\n",
    "    thisrow = sorted(outcome for outcome in dist if outcome.startswith(first))\n",
    "    return '<tr>' + cat(cell(outcome, event, condition) for outcome in thisrow) + '</tr>'\n",
    "\n",
    "def cell(outcome, event, condition): \n",
    "    \"Display outcome in appropriate color.\"\n",
    "    color = ('lightgreen' if event(outcome) and condition(outcome) else\n",
    "             'yellow' if condition(outcome) else\n",
    "             'white')\n",
    "    return '<td style=\"background-color: {}\">{}</td>'.format(color, outcome)    \n",
    "\n",
    "cat = ''.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the all possible outcomes\n",
    "# white cells: no two ferrari wins\n",
    "# colored cells: at least one ferrari win on a rainy day\n",
    "# green cells: two ferrari wins with at least one of them on a rainy day\n",
    "Pgrid(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count.\n",
    "\n",
    "Number of cells where Ferrari wins at least once on a rainy day = 12 + 12 + (12 - 2) + (12 - 2) = 44\n",
    "Number of cells where Ferrari wins both races = 3 + 3 + 3 + 3 = 12\n",
    "And so probability of two Ferrari wins given that Ferrari won at least once race on a cloudy day is 12 / 44 = 27%.\n",
    "\n",
    "å¯¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's color a slightly bigger table. Let's increase the amount of data to Mercedes, Ferrari, Renault, and Williams. Also, let's add (c)loudy day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning one race. Ferrari is SV and KR\n",
    "RGPr = ProbDist(\n",
    "    LH = 281,\n",
    "    SV = 241,\n",
    "    VB = 174,\n",
    "    KR = 171,\n",
    "    NH = 53,\n",
    "    CS = 38,\n",
    "    LS = 6,\n",
    "    SS = 1)\n",
    "RGPr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning a race on a specific weather condition\n",
    "RGPrw  = joint(RGPr, Uniform('rsc'), '') #care about the weather\n",
    "RGPrw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning two races on specific weather conditions\n",
    "RJGPrw  = joint(RGPrw, RGPrw)\n",
    "len(RJGPrw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, that's a 24 x 24 table, the square of our previous table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pgrid(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the counting is similar: \n",
    "\n",
    "24 + 24 + (24 - 2) + (24 - 2) = 92 yellow cells\n",
    "5 + 5 + 5 + 5 = 20 green cells\n",
    "\n",
    "So probability of two Ferrari wins given at least one Ferrari win on a rainy day = 20/92 = 22%.\n",
    "\n",
    "And so it makes sense that for all of Formula 1 drivers and all 5 weather conditions, that the probability hovers around 25%. Do you want to run this? Sorry, I am not going to risk frying my kernel, but you can :-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you may have gotten confused when I added evidence to a probability distribution, and you wondered how **the heck** are weather conditions related to F1 rankings? But you were thinking too hard. Probability theory is just counting. Given all possible outcomes, figure out the joint sample space, and just count favorable outcomes over all possible outcomes.\n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/elementary.png\" width=300 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you know what's the strangest thing? A Ferrari win on a rainy day is understandable, because Ferrari has great Pirelli tires, and once I figure that out, I'm ready to bet on Ferrari on rainy days. But if i told you that Ferrari wins on the day it rains... in Australia (not on the race track), and that there are 5 possible weather conditions in Australia, *the same listing of cells above holds*! Same sample space, same favorable outcomes and unfavorable ones!\n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/cmon-iceage.png\" width=200 />\n",
    "</center>\n",
    "\n",
    "You may say... \"Wait a minute, if this theory that you call probability theory gives me illogical answers, how can I trust it\"? \n",
    "\n",
    "Probability theory is mathematically sound, but it all comes down to **the model you apply it to**. \n",
    "\n",
    "If your sample space is the joint distribution of F1 drivers, and.. weather conditions **in Australia**, then you've probably built the wrong statistical model, and there ain't a single Machine Learning algorithm that will help you here. Junk in, junk out. But weather on race tracks and F1 racing, that does make sense, right? Skills of drivers, performance of tires..\n",
    "\n",
    "That is why the model is so important in Data Science. Before you start applying statistics to data, or feeding data into a Machine, you need to work on your model. In the case of discrete random variables, your pdf is a dictionary, much like our Danish or Formula 1 exemplars: Even though you have *some* data based on *some* experiment, you still need to build a model with joint distributions to complete your sample space for the problem at hand. In the case of continuous random variables your state space is most often infinite (countable or uncountable) and you need to build a much denser model. In fact, a high dimensional manifold in state space.\n",
    "\n",
    "Statistics is the field of mathematics which deals with the understanding and interpretation of data. Specifically, you want to find the underlying mechanism that yields the data you're analyzing. You took the first step by learning probability theory. Now we'll begin to catalog all possible probability distributions that lead to seemingly random data (Poisson, gaussian, exponential, etc), and by shaping models with Bayesian inference: You match the histogram of your data to a pdf on the catalogue, you find its parameters using probabilistic programs like variational inference or Monte Carlo methods, and once you have your analytic model, you extract all kinds of interesting statistics from it (instead of from the data).\n",
    "\n",
    "In fact, that is exactly what machines do. They use a deep neural structure to build a pdf, which they can then use for prediction. Machine Learning experts have stronger stats foundation than CS undergraduates in a deep learning class. Information theory, in general, requires a strong understanding of data and probability (and linear algebra), and anyone interested in becoming a Data Scientist or Machine Learning Engineer needs to develop a deep intuition of statistical (and linear algebra) concepts. That is our journey in this class.\n",
    "\n",
    "In many cases, predictive Machine Learning algorithms are completely useless in helping with the understanding of data. They do not yield their data model. Bayesian ML will change all that, and Alexa will be able to tell you why it lowered room temperature, John."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
