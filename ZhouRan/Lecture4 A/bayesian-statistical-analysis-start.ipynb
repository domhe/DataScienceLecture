{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Sci Engineering Methods and Tools, Lecture 4 Day 1</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 4 February 2019, with material from Peter Norvig and Chris Fonnesbeck</div>\n",
    "\n",
    "# Bayesian Statistical Analysis\n",
    "\n",
    "*Bayesian* statistics is not just a particular statistical method. It is an completely different and very successful paradigm for doing statistical analysis.\n",
    "\n",
    "A Bayesian model is described by parameters and uncertainty in those parameters. The model is described as probability distributions, which we had time to experiment with. Uncertainly in its parameters is *also* described as probability distributions. That is why you need a solid foundation in probability theory.\n",
    "\n",
    "In the case of Big Data, we have so much data that we know exactly what the probability distributions may be. Uncertainties not required. Oftentimes, even in the case of Big Data sometimes, there are conditions where **not enough data is available**, e.g. snowing with sun glare and white trucks. That is when accidents happen with autonomous vehicles!\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/autonomous.png\" width=400 />\n",
    "</center>\n",
    "\n",
    "Run the cell below, we'll use it.\n",
    "```python\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "RANDOM_SEED = 20090425\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability Distributions\n",
    "\n",
    "Let $Z$ be a random variable. Associated with $Z$ is a *probability distribution function* that assigns probabilities to the different outcomes $Z$ can take. Graphically, a probability distribution is a curve where the probability of an outcome on the x-axis is the value of the curve on the y-axis.\n",
    "\n",
    "We can divide random variables into three classifications:\n",
    "\n",
    "-   **$Z$ is discrete**: Discrete random variables are *categorical*: They may only assume values on a specified list. In R, we call these values `factors`. Might as well call them `factors` in python. Movie ratings are an example of a discrete random variables. \n",
    "\n",
    "-   **$Z$ is continuous**: Continuous random variable can take on arbitrarily exact values. For example, temperature, speed, time, color are all modeled as continuous variables because you can progressively make the values more and more precise.\n",
    "\n",
    "- **$Z$ is mixed**: Mixed random variables assign probabilities to both discrete and continuous random variables, i.e. it is a combination of the above two categories. \n",
    "\n",
    "### Discrete Case\n",
    "If $Z$ is discrete, then its distribution is called a *probability mass function*, which measures the probability $Z$ takes on the value $k$, denoted $P(Z=k)$. Note that the probability mass function completely describes the random variable $Z$, that is, if we know the mass function, we know how $Z$ should behave. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Expectation of a random variable\n",
    "\n",
    "In probability theory, the *expectation*, or *expected value* of a random variable is what the frequentists would denote.. the long-run average value of repetitions of the experiment it represents. For example, the expected value in rolling a six-sided die is 3.5, because the average of all the numbers that come up in an extremely large number of rolls is close to 3.5 (why isn't it 3?).\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/average3.5.png\" width=400 />\n",
    "</center>\n",
    "\n",
    "Probability explanation:\n",
    "$$(1 * \\frac 16) + (2 * \\frac 16) + (3 * \\frac16) + (4 * \\frac16) + (5 * \\frac16) + (6 * \\frac16)$$\n",
    "\n",
    "The mathematical definition of Expectation is the following: The expected value of a discrete random variable is the probability-weighted average of all possible values. In other words, each possible value the random variable can assume is multiplied by its probability of occurring, and the resulting products are summed to produce the expected value. So, for Formula 1 drivers, the Expectation of a Mercedes win is the sum of the probability of a Lewis Hamilton win and the probability of Sebastian Vetel win.\n",
    "\n",
    "The same principle applies to a continuous random variable, except that the **sum** is replaced with the **integral of the variable with respect to its probability density**.\n",
    "\n",
    "The expected value is a *key* aspect of how one characterizes a probability distribution; it is one type of *location* parameter. By contrast, the **variance**, another *key* value, is a measure of *dispersion* of the possible values of the random variable around the expected value. \n",
    "\n",
    "Let $X$ be a random variable with a finite number of finite outcomes $x_1,  x_2, ..., x_k$ occurring with probabilities  $p_1,  p_2, ...,  p_k$, respectively. The expectation of $X$ is defined as\n",
    "\n",
    "$[X] = x_1 p_1  + x_2 p_2 + ... + x_k p_k$\n",
    "\n",
    "Since all probabilities $p_{i}$ add up to 1, the expected value is the weighted average, with $p_i$â€™s being the weights.\n",
    "\n",
    "The Expectation of a Ferrari win is\n",
    "\n",
    "$[\\text{Ferrari}] = LH p(LH)  + SV p(SV)$\n",
    "\n",
    "If all outcomes $x_i$ are equiprobable (that is, $p_1 = p_2 = ... = p_k$), then the weighted average turns into the simple average. This is intuitive: the expected value of a random variable is the average of all values it can take; thus the expected value is what one expects to happen on average.\n",
    "\n",
    "The law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the **expectation**, mathematical expectation, EV, average, mean value, mean, or **first moment**.\n",
    "\n",
    "Go [here](https://en.wikipedia.org/wiki/Expected_value) for more math.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Inference\n",
    "\n",
    "Statistical inference is the process of learning from incomplete or error-contaminated data. We account for this incompleteness and imperfection using either a sampling model with incomplete samples or errors in measurement.\n",
    "\n",
    "### Statistical hypothesis testing\n",
    "\n",
    "The *de facto* non-Bayesian standard for statistical inference is called **statistical hypothesis testing**. The goal of hypothesis testing is to evaluate a **null hypothesis**. The null hypothesis is when two statistical groups are *not different*. There are two possible outcomes:\n",
    "\n",
    "- Reject the null hypothesis\n",
    "- Accept the null hypothesis\n",
    "\n",
    "Rejection occurs when a test statistic is higher than some pre-specified threshold valuel. Acceptance occurs when it's lower.\n",
    "\n",
    "Pharmaceutical companies run null hypothesis tests all the time. Their null test is whether the drug group's statistics on recovery is sufficiently different from the placebo group. This test is conducted in what is called *double-blind* circumstances.\n",
    "\n",
    "Setting up a statistical test involves several subjective choices by the user that are rarely justified based on the problem or decision at hand. Choices are often based on arbitrary criteria, including \"statistical tradition\" (Johnson 1999). The resulting evidence is indirect, incomplete, and typically overstates the evidence against the null hypothesis (Goodman 1999).\n",
    "\n",
    "The results of statistical hypothesis tests are very easy to misinterpret. But we'll review the principal ones in class. \n",
    "\n",
    "### Frequentist and Bayesian Estimation \n",
    "\n",
    "Instead of testing, a more informative and effective approach for inference is based on **estimation**, which can be frequentist or Bayesian. That is, rather than testing whether two statistical groups are different, let's estimate *how different* they are by **modeling them!** \n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/manU.png\" width=300 />\n",
    "</center>\n",
    "\n",
    "Additionally, we include an estimate of **uncertainty** associated with that difference, which includes uncertainty due to our lack of knowledge of model parameters (*epistemic uncertainty*) and uncertainty due to the inherent stochasticity of the system (*aleatory uncertainty*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian vs Frequentist Statistics: *What's the difference?*\n",
    "\n",
    "Any statistical inference paradigm, Bayesian or otherwise, involves at least the following: \n",
    "\n",
    "1. Some **unknown quantities** about which we are interested in learning or testing. We call these *parameters*. These are also called **dependent variables**.\n",
    "2. Some **data** which have been observed, and hopefully contain information about the parameters. These are called the **independent variables**.\n",
    "3. One or more **models** that relate the data to the dependent parameters. The model is the instrument used to learn. For example, you learn about the real world from the model that your parents built for you, before you can leave home to see the real thing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist World View\n",
    "\n",
    "- **Data** observed is considered **random**, because it is the realization of random processes and hence will vary each time one goes to observe the system.\n",
    "- Model **parameters** are considered **fixed**. A parameter's true value is uknown but fixed. For example, Jesus Christ is a central parameter in the Christian World Model. Christians will say the world order may be random because of human misgivings, but Jesus Christ and his compassion is fixed and steadfast.\n",
    "\n",
    "In mathematical notation, this implies a general model of the form:\n",
    "\n",
    "<div style=\"font-size:20px\">\n",
    "\\\\[f(y \\; | \\; \\theta)\\\\]\n",
    "</div>\n",
    "\n",
    "Here, the model \\\\(f\\\\) accepts data values \\\\(y\\\\) as an argument, conditional on fixed values of \\\\(\\theta\\\\).\n",
    "\n",
    "Frequentist inference typically involves deriving **estimators** for unknown parameters. Estimators are formulae that return estimates for particular parameters as a function of data. They are selected based on some chosen optimality criterion, such as *unbiasedness*, *variance minimization*, or *efficiency*.\n",
    "\n",
    "In a frequentist world, new estimators need to be derived for every parameter $\\theta$ introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian World View\n",
    "\n",
    "- Data is considered **fixed**. It used to be random, but once stored in your lab notebook or spreadsheet, it does not change.\n",
    "- Model parameters may not be random, but Bayesians use probability distribtutions to describe their uncertainty in values, and are therefore treated as **random**. In some cases, it is useful to consider parameters as having been sampled from probability distributions. For example, some Christians may postulate that world order is predetermined, however Jesus Christ's compassion may vary because sometimes he gets exasperated by his followers.\n",
    "\n",
    "This implies the following form:\n",
    "\n",
    "<div style=\"font-size:20px\">\n",
    "\\\\[p(\\theta \\; | \\; y)\\\\]\n",
    "</div>\n",
    "\n",
    "This formulation used to be referred to as ***inverse probability***, because it infers from observations to parameters, or from effects to causes.\n",
    "\n",
    "Bayesians do not seek new estimators for every estimation problem they encounter. There is only one estimator for Bayesian inference: **Bayes' Formula**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Formula\n",
    "\n",
    "While frequentist statistics uses different estimators for different problems, Bayes formula is the **only estimator** that Bayesians need to obtain estimates of unknown quantities. \n",
    "\n",
    "The equation expresses how our belief about the value of \\\\(\\theta\\\\) (parameters), as expressed by the **prior distribution** \\\\(P(\\theta)\\\\) is reallocated following the observation of the data \\\\(y\\\\).\n",
    "\n",
    "The denominator \\\\(p(y)\\\\) usually cannot be computed directly, and is actually the expression in the numerator integrated over all possible model parameters \\\\(\\theta\\\\):\n",
    "\n",
    "In the continuous case, this is Bayes' formula:\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "\\\\[Pr(\\theta\\;|\\;y) = \\frac{Pr(y\\;|\\;\\theta)Pr(\\theta)}{\\int Pr(y\\;|\\;\\theta)Pr(\\theta) d\\theta}\\\\]\n",
    "</div>\n",
    "\n",
    "The intractability of this integral led to the under-utilization of Bayesian methods by statisticians. But with the advent of computers and clever algorithms like Metropolis-Hastings, this has changed.\n",
    "\n",
    "### Priors\n",
    "\n",
    "The **prior distribution** characterizes what is known about an unknown quantity before observing the data from the present study. Thus, it represents the information state of that parameter. It can be used to reflect the information obtained in previous studies, to constrain the parameter to plausible values, or to represent the population of possible parameter values, of which the current study's parameter value can be considered a sample.\n",
    "\n",
    "### Likelihood functions\n",
    "\n",
    "The **likelihood** represents the information in the observed data (or evidence), and is used to update prior distributions to **posterior distributions**. This updating of your belief is justified becuase of the **likelihood principle**, which states:\n",
    "\n",
    "> Following observation of \\\\(y\\\\), the likelihood \\\\(L(\\theta\\;|\\;y)\\\\) contains all experimental information from \\\\(y\\\\) about the unknown \\\\(\\theta\\\\).\n",
    "\n",
    "Likelihood is closely related to the probability density (or mass) function. The difference is that the likelihood varies the parameter while holding the observations constant, rather than *vice versa*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference, in 3 Easy Steps\n",
    "\n",
    "[Gelman et al. (2013)](http://www.stat.columbia.edu/~gelman/book/) describes the process of conducting Bayesian statistical analysis in 3 steps:\n",
    "\n",
    "## Step 1: Specify a probability model\n",
    "\n",
    "Bayesian statistics involves using probability models to solve problems. So, the first task is to *completely specify* the model in terms of probability distributions. This includes everything: unknown parameters, data, covariates, missing data, predictions. All must be assigned some probability density function (pdf).\n",
    "\n",
    "Let's look at two examples of pdfs, one for discrete variables, another for continuous variables. Actually, for discrete variables, the probability density function is called a *probability mass function*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Poisson distribution\n",
    "\n",
    "For Discrete Random Variables, the Poisson distribution models unbounded counts:\n",
    "\n",
    "$$X = \\{0,1,2,3,\\ldots \\}$$\n",
    "\n",
    "$$Y = \\{\\ldots,-2,-1,0,1,2,\\ldots\\}$$\n",
    "\n",
    "Its Probability Mass Function: \n",
    "\n",
    "$$Pr(X=x) = f(x\\;|\\; \\theta)$$\n",
    "\n",
    "![Discrete variable](http://upload.wikimedia.org/wikipedia/commons/1/16/Poisson_pmf.svg)\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "$$Pr(X=x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}$$\n",
    "</div>\n",
    "\n",
    "* $X=\\{0,1,2,\\ldots\\}$\n",
    "* $\\lambda > 0$\n",
    "\n",
    "One useful property of the Poisson distribution is that its *expected value* is equal to its parameter, i.e.:\n",
    "\n",
    "$$E(X) = \\text{Var}(X) = \\lambda$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take random samples from a Poisson distribution and plot their histogram. You will see it reproduces a Poisson distribution. That is to say, random samples from a Poisson process yields a Poisson Distribution. This means that the statistics of a Poisson process are not exactly completely random. Rather, they follow a predictable behavior.\n",
    "\n",
    "That is because Poisson processes model counts. For example, counts of SMS messages you receive per day. Let's say, if you're a popular student, you receive from 0 to 100 messages a day. On every single day, I can thus expect you receive about 50 messages, right? It's a rare day you receive 0, or 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Poisson\n",
    "\n",
    "x = Poisson.dist(mu=1)\n",
    "samples = x.random(size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples, bins=len(set(samples)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the probability mass distribution for different $\\lambda$ values. Yes, we will use `scipy` even though we have not introduced that package yet because it has nice models of the Poisson.\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"http://www.ticotimes.net/wp-content/uploads/2015/10/Sloth-1.jpg\" width=\"400\" />\n",
    "Lazy Professor!\n",
    "</center>\n",
    "\n",
    "Copy the code below and paste it into the code cell further below and execute the code cell.\n",
    "```python\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "figsize(10, 4)\n",
    "\n",
    "import scipy.stats as stats\n",
    "a = np.arange(16)\n",
    "poi = stats.poisson\n",
    "lambda_ = [1.5, 4.25]\n",
    "colours = [...]\n",
    "\n",
    "plt.bar(a, poi.pmf(a, lambda_[0]), color=colours[0],\n",
    "        label=\"$\\lambda = %.1f$\" % lambda_[0], alpha=0.60,\n",
    "        edgecolor=colours[0], lw=\"3\")\n",
    "\n",
    "plt.bar(a, poi.pmf(a, lambda_[1]), color=colours[1],\n",
    "        label=\"$\\lambda = %.1f$\" % lambda_[1], alpha=0.60,\n",
    "        edgecolor=colours[1], lw=\"3\")\n",
    "\n",
    "plt.xticks(a + 0.4, a)\n",
    "plt.legend()\n",
    "plt.ylabel(\"probability of $k$\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.title(\"Probability mass function of a Poisson random variable; differing \\\n",
    "$\\lambda$ values\");\n",
    "```\n",
    "\n",
    "\"#348ABD\" and \"#A60628\" are good options for color. Also, go [here](http://www.colorsontheweb.com/) to find all colors on the Web. Also, add a third value of $\\lambda$, just for kicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Normal Distribution\n",
    "\n",
    "Also known as the **gaussian** distribution.\n",
    "\n",
    "For continuous Random Variables:\n",
    "\n",
    "$$X \\in [0,1]$$\n",
    "\n",
    "$$Y \\in (-\\infty, \\infty)$$\n",
    "\n",
    "**Probability Density Function**: \n",
    "\n",
    "For continuous $X$,\n",
    "\n",
    "$$Pr(x \\le X \\le x + dx) = f(x|\\theta)dx \\, \\text{ as } \\, dx \\rightarrow 0$$\n",
    "\n",
    "![Continuous variable](https://upload.wikimedia.org/wikipedia/commons/7/74/Normal_Distribution_PDF.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 110%;\">  \n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left[-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right]$$\n",
    "</div>\n",
    "\n",
    "* $X \\in \\mathbf{R}$\n",
    "* $\\mu \\in \\mathbf{R}$\n",
    "* $\\sigma>0$\n",
    "\n",
    "$$\\begin{align}E(X) &= \\mu \\cr\n",
    "\\text{Var}(X) &= \\sigma^2 \\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Normal\n",
    "\n",
    "y = Normal.dist(mu=-2, sd=4)\n",
    "samples = y.random(size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Exponential distribution\n",
    "\n",
    "An example of continuous random variable is a random variable with *exponential density*. The density function for an exponential random variable looks like this:\n",
    "\n",
    "$$f_Z(z | \\lambda) = \\lambda e^{-\\lambda z }, \\;\\; z\\ge 0$$\n",
    "\n",
    "Like a Poisson random variable, an exponential random variable can take on only non-negative values. But unlike a Poisson variable, the exponential can take on *any* non-negative values, including non-integral values such as 3.1415629. This property makes it a poor choice for count data, which must be an integer, but a great choice for time data, temperature data, or any other precise *and positive* variable.  \n",
    "\n",
    "When a random variable $Z$ has an exponential distribution with parameter $\\lambda$, we say *$Z$ is exponential* and write\n",
    "\n",
    "$$Z \\sim \\text{Exp}(\\lambda)$$\n",
    "\n",
    "Given a specific $\\lambda$, the expected value of an exponential random variable is equal to the inverse of $\\lambda$, that is:\n",
    "\n",
    "$$E[\\; Z \\;|\\; \\lambda \\;] = \\frac{1}{\\lambda}$$\n",
    "\n",
    "Let's plot two probability density functions with different $\\lambda$ values.\n",
    "```python\n",
    "a = np.linspace(0, 4, 100)\n",
    "expo = stats.expon\n",
    "lambda_ = [0.5, 1]\n",
    "\n",
    "for l, c in zip(lambda_, colours):\n",
    "    plt.plot(a, expo.pdf(a, scale=1./l), lw=3,\n",
    "             color=c, label=\"$\\lambda = %.1f$\" % l)\n",
    "    plt.fill_between(a, expo.pdf(a, scale=1./l), color=c, alpha=.33)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"PDF at $z$\")\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.ylim(0,1.2)\n",
    "plt.title(\"Probability density function of an Exponential random variable;\\\n",
    " differing $\\lambda$\");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate a posterior distribution\n",
    "\n",
    "The mathematical form \\\\(p(\\theta \\;|\\; y)\\\\) that we associated with the Bayesian approach is referred to as a **posterior distribution**.\n",
    "\n",
    "> posterior /posÂ·terÂ·iÂ·or/ (pos-tÄ“rÂ´e-er) later in time; subsequent.\n",
    "\n",
    "Why posterior? Because it tells us what we know about the unknown \\\\(\\theta\\\\) *after* having observed \\\\(y\\\\).\n",
    "\n",
    "This posterior distribution is formulated as a function of the probability model that was specified in Step 1. Usually, we can write it down but we cannot calculate it analytically. In fact, the difficulty inherent in calculating the posterior distribution for most models of interest was the major contributing factor for the slow adoption of Bayesian methods for data analysis. \n",
    "\n",
    "**But**, once the posterior distribution is calculated, you get:\n",
    "\n",
    "- point estimates\n",
    "- credible intervals\n",
    "- quantiles\n",
    "- predictions\n",
    "\n",
    "## Step 3: Check your model\n",
    "\n",
    "It is important that the model and its outputs be assessed before using outputs for inference. Models are specified based on assumptions that are largely unverifiable, so the least we can do is examine the output in detail, relative to the specified model and the data that were used to fit the model.\n",
    "\n",
    "Specifically, we must ask:\n",
    "\n",
    "- does the model fit data?\n",
    "- are the conclusions reasonable?\n",
    "- are the outputs sensitive to changes in model structure?\n",
    "\n",
    "That is why, when building a model from data, we earmark some 20% of the data and ignore it while building the model. Then we compare model output from part of that 20% and verify it matches the other part of the 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In search of  $\\lambda \\;$\n",
    "\n",
    "Suppose we are given some data and we are told that there is a process that yields this data, and which we must try to model. Whether we're fitting a discrete or continuous model, we must determine the right parameter(s) $\\lambda$ for the data. Why do we want to know $\\lambda$? Well, the expected value of a random variable is either equal to $\\lambda$ (discrete case, Poisson distribution), or to the inverse of $\\lambda$ (continuous case, exponential distribution. So if we want the expectation of a process that yields the data we want to model, we need to figure out $\\lambda$.\n",
    "\n",
    "But $\\lambda$ is hidden from us. We see only $Z$, and must go backwards to try and determine $\\lambda$ to build the best possible model of our data. The problem is difficult because there is no one-to-one mapping from $Z$ to $\\lambda$. Many different methods have been created to solve the problem of estimating $\\lambda$, and since $\\lambda$ is never actually observed, no one can say for certain which method is best! \n",
    "\n",
    "Bayesian inference is concerned with *beliefs* about what $\\lambda$ might be. Rather than try to guess $\\lambda$ exactly, we can only talk about what $\\lambda$ is likely to be by assigning a probability distribution to $\\lambda$. \n",
    "\n",
    "**This is not the probability distribution of your model! This is a different probability distribution, one for each parameter of your model!**\n",
    "\n",
    "This is odd... After all, $\\lambda$ is fixed; it is not random! How can we assign probabilities to values of a non-random variable? [Sacrebleau](https://en.wikipedia.org/wiki/Sacrebleu), that is what frequentists might say!\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"https://vignette.wikia.nocookie.net/tintin/images/0/07/Haddock_sword.jpg\" width=\"300\" />\n",
    "Sacrebleau!\n",
    "</center>\n",
    "\n",
    "But recall that Bayesians easily *assign* probabilities by interpreting them as *beliefs*. And it is entirely acceptable to have *beliefs* about the parameter $\\lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab #1: Your first Bayesian Model for a simple dataset\n",
    "\n",
    "Let's do statistical inference for one dataset (one statistic). \n",
    "\n",
    "We'll use Gelman et al.'s famous (2007) radon dataset. In this dataset the amount of the radioactive gas radon has been measured among different households in all counties of the great state of Minnesota (MN). Radon gas is known to be the highest cause of lung cancer in non-smokers. It is believed to be more strongly present in households containing a basement and to differ in amount present among different types of soil.\n",
    "\n",
    ">  The US EPA has set an action level of 4 pCi/L. At or above this level of radon, the EPA recommends you take corrective measures to reduce your exposure to radon gas.\n",
    "\n",
    "Let's import the dataset and pretty-view the first 5 rows with `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radon = pd.read_csv('data/radon.csv', index_col=0)\n",
    "radon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the (log) radon levels measured in a single county: The county of Hennepin.\n",
    "\n",
    "Why are we using the log of the Radon measurement? To squash the measurement as much as possible into a single order of magnitude.\n",
    "\n",
    "Suppose we are interested in the following point statistics:\n",
    "\n",
    "- Whether the mean log-radon value is greater than 4 pCi/L in Hennepin county\n",
    "- The probability that any randomly-chosen household in Hennepin county has a reading of greater than 4\n",
    "\n",
    "Seaborn's `distplot` computes the histogram *and also fits it to a curve*. See [here](https://seaborn.pydata.org/generated/seaborn.distplot.html) for the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hennepin_radon = radon.query('county==\"HENNEPIN\"').log_radon\n",
    "sns.distplot(hennepin_radon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this confirms that a pdf is a function of *one* variable\n",
    "hennepin_radon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "Recall that the first step in Bayesian inference is specifying a **full probability model** for the problem.\n",
    "\n",
    "This consists of:\n",
    "\n",
    "- A likelihood function(s) for the observations\n",
    "- Priors for all unknown quantities\n",
    "\n",
    "The measurements look approximately normal (gaussian), so let's start by **assuming a normal distribution as the sampling distribution (likelihood) for the data**.\n",
    "\n",
    "* This is a very common approach to building a Bayesian model: Get the histogram, see if it looks like Poisson, Normal, Exponential, or a bunch of other analytic pdf's we'll introduce (like the Beta and Gamma distributions), and try to fit the data to a model of the distribution by varying the distribution's paramter(s).\n",
    "\n",
    "Let's pick a Normal distribution, which is described by its two paramaters $\\mu$ (mean) and $\\sigma$ (standard deviation):\n",
    "\n",
    "$$y_i \\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "This implies that we have 2 unknowns in the model; the mean and standard deviation of the distribution. The ones we pick as initial SWAGs consist of our *priors*. The funky thing about the priors: They are themselves probability density functions!\n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/dog-chase-tail.jpg\" width=300 />\n",
    "</center>\n",
    "\n",
    "#### Prior choice\n",
    "\n",
    "How do we choose distributions to use as priors for parameters $\\mu$ and $\\sigma$? \n",
    "\n",
    "There are several considerations:\n",
    "\n",
    "- Discrete vs continuous values\n",
    "- The support of the variable\n",
    "- The available prior information\n",
    "\n",
    "While there may likely be prior information about the distribution of radon values, we will assume no prior knowledge, and specify a **diffuse** prior for each parameter.\n",
    "\n",
    "Since the mean can take any real value (since it is on the log scale), we will use another normal distribution here, and specify a *large* variance to allow the possibility of very large or very small values:\n",
    "\n",
    "$$\\mu \\sim N(0, 10^2)$$\n",
    "\n",
    "For the standard deviation, we know that the true value must be positive (no negative variances!). Let's choose a [uniform](http://mathworld.wolfram.com/UniformDistribution.html) prior bounded from below at zero and from above at a value that is sure to be higher than any plausible value the true standard deviation (on the log scale) could take. That way, we are sure to capture the real value, somewhere in -between.\n",
    "\n",
    "$$\\sigma \\sim U(0, 10)$$\n",
    "\n",
    "How did I know to pick these? In one word: *Experience*. It's the same as Machine Learning. There are a lot of points where you have to make good guesses about **hyperparameters**.\n",
    "\n",
    "We now encode these in a Python model, using the PyMC3 package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing PyMC3\n",
    "-----\n",
    "\n",
    "PyMC3 is a Python library for programming Bayesian analysis; see [here](https://doi.org/10.7717/peerj-cs.55). It's a pretty fantastic package. Looky [here](https://docs.pymc.io/) for its API and docs.\n",
    "\n",
    "We will model the problem above using PyMC3. This type of programming is called *probabilistic programming*, and it is probabilistic in that we create probability models using programming variables as the model's components. Model components are first-class primitives within the PyMC3 framework. \n",
    "\n",
    ">   Another way of thinking about this: unlike a traditional program, which only runs in the forward directions, a probabilistic program is run in both the forward and backward direction. It runs forward to compute consequences of assumptions it contains about the model, but also backward from the data to constrain possible explanations. In practice, many probabilistic programming systems will cleverly interleave forward and backward operations to efficiently home in on the best explanations.  - [Cronin, Beau. \"Why Probabilistic Programming Matters.\" 24 Mar 2013. Google, Online Posting to Google . Web. 24 Mar. 2013]( https://plus.google.com/u/0/107971134877020469960/posts/KpeRdJKR6Z1)\n",
    "\n",
    "PyMC3 used to rely on `theano`, a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently, and which we will revisit when we study machine learning. Theano is the brainchild of Yoshua Benjio of the University of Montreal's [MILA](https://mila.quebec/en/) laboratory. In my opinion, it's the most famous university lab associated to artificial neural networks and deep learning. It's pretty [well-funded](http://nouvelles.umontreal.ca/en/article/2017/09/15/facebook-invests-over-7m-u.s.-in-mila-and-ai-research-in-montreal/).\n",
    "\n",
    "Unfortunately, `theano` is slowly being deprecated because other libraries like facebook's `Torch` and Google's `TensorFlow` now include the same features. PyMC3 still uses theano, but the newer versions probably don't.\n",
    "\n",
    "For probabilistic programming, you write a program in Python that builds expressions for Theano. You still have to declare variables $a,b,c$ and give their types $(int, int, int)$, build expressions for how to put those variables together $a^b + c$, and compile expression graphs to functions $Pow(a,b,c)$ in order to use them for computation. What theano builds in return is a super-fast callable object from a purely symbolic graph, optimizes the graph, and even compiles some or all of it into native machine instructions. More on Theano [here](http://www.deeplearning.net/software/theano/). So we need to import that library.\n",
    "\n",
    "On Windows, from the Start menu, search for and open `Anaconda Prompt`. On MacOS, open Launchpad, then click the Terminal icon. On Linux, open a Terminal window. Now in these windows, type `conda install -c mila-udem theano pygpu`. Don't try `!conda install theano` in a jupyter notebook code cell because it may fry your jupyter notebook's kernel. Wait until success. Then in that same terminal, type `conda install pymc3`. Wait until success.\n",
    "\n",
    "PyMC3 code is easy to read. The only novel thing should be the syntax. Simply remember that we are representing the model's components ($\\tau, \\lambda_1, \\lambda_2$ ) as variables. \n",
    "\n",
    "Then execute the following cell. We name our model and define our priors as the pdf's we mentionned above. Notice priors are most often given greek variable names. The parameters for the priors (the parameters for the parameters of our model, also sometimes called *hyperparameters*) were really just silly guesses, and you have to learn to start with good guesses in data science ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Model, Uniform\n",
    "\n",
    "with Model() as radon_model:\n",
    "    Î¼ = Normal('Î¼', mu=0, sd=10)\n",
    "    Ïƒ = Uniform('Ïƒ', 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Bayesian Software\n",
    "> There is a good amount of software options for Bayesians, including both open source software (*e.g.*, Stan, PyMC3, JAGS, emcee) and commercial (*e.g.*, SAS, Stata). Your instructor happens to love `PyMC3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that remains is to add the likelihood, which takes $\\mu$ and $\\sigma$ as parameters, and the log-radon values as the set of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with radon_model:    \n",
    "    y = Normal('y', mu=Î¼, sd=Ïƒ, observed=hennepin_radon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit the model using a numerical approach called [variational inference](https://www.cs.jhu.edu/~jason/tutorials/variational.html). This will estimate the posterior distribution using an optimized approximation, and then draw samples from it. This is complicated math. You may read the paper I uploaded on blackboard, but do not worry too much if you don't understand. Computers do all the legwork. We just sit back and watch GoT while they work.\n",
    "\n",
    "- When you execute the cell below, wait for a pink band to appear. Do not move to another cell before the pink band appears and the computation completes. It may take your laptop a full minute before the pink band appears, and another 30 seconds for the computation to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import fit\n",
    "\n",
    "with radon_model:\n",
    "\n",
    "    samples = fit(random_seed=RANDOM_SEED).sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did is fit the best possible analytical gaussian model to the `hennepin_radon` dataset by picking various values of the $\\mu$ and $\\sigma$ parameters, by varying them across their own probability distributions, which we specified. Actually, PyMC3 did the work, and we watched :-)\n",
    "\n",
    "Now we're ready to plot our posterior, which is the best possible values for $\\mu$ and $\\sigma$ that PyMC3 evaluated for us. In other words, the values of $\\mu$ and $\\sigma$ that result in the best possible $N(\\mu, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import plot_posterior\n",
    "\n",
    "plot_posterior(samples, varnames=['Î¼'], ref_val=np.log(4), color='LightSeaGreen');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the posterior distribution of $\\mu$, along with an estimate of the 95% posterior **credible interval**. \n",
    "\n",
    "The output\n",
    "\n",
    "    83.1% < 1.38629 < 16.9%%\n",
    "    \n",
    "informs us that the probability of $\\mu$ being less than $\\log(4)$ is 83.1%% and the corresponding probability of being greater than $\\log(4)$ is 16.9%.\n",
    "\n",
    "> **Answer**: The posterior probability that the mean level of household radon in Henneprin County is greater than 4 pCi/L is 0.17.\n",
    "\n",
    "No questions about the standard deviation, but let's plot it, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior(samples, varnames=['Ïƒ'], ref_val=0.8, color='LightSeaGreen');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "What is the probability that a given household has a log-radon measurement larger than one? To answer this, we make use of the **posterior predictive distribution**.\n",
    "\n",
    "$$p(z \\;| \\; y) = \\int_{\\theta} p(z \\;| \\; \\theta) p(\\theta \\; | \\; y) d\\theta$$\n",
    "\n",
    "where here $z$ is the predicted value and y is the data used to fit the model.\n",
    "\n",
    "The posterior predictive distribution accounts for uncertainty about $\\theta$. We should refrain from plugging in a single best estimate $\\hat{\\theta}$ for $\\theta$, because it ignores uncertainty about $\\theta$, and because a source of uncertainty is ignored, the predicted distribution will be too narrow (extreme values of $\\tilde {x}$ will occur more often than the posterior distribution suggests).\n",
    "\n",
    "The posterior distribution of possible $\\theta$ values depends on $\\mathbf {X}$: $p(\\theta \\; | \\; \\mathbf {X} )$. And the posterior predictive distribution of $\\tilde {x}$ given $\\mathbf {X}$ is calculated by marginalizing the distribution of $\\tilde {x}$ given $\\theta$ over the posterior distribution of $\\theta$ given $ \\mathbf {X}$. That is the integral above. See [here](https://en.wikipedia.org/wiki/Posterior_predictive_distribution) for more explanation.\n",
    "\n",
    "We can estimate the probability that a given household has a log-radon measurement larger than one from the posterior samples of the parameters in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = samples['Î¼']\n",
    "sigmas = samples['Ïƒ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "radon_samples = Normal.dist(mus, sigmas).random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(radon_samples > np.log(4)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer*: The posterior probability that a randomly-selected household in Henneprin County contains radon levels in excess of 4 pCi/L is 0.47."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model checking\n",
    "\n",
    "***How do we know our model is any good?***\n",
    "\n",
    "It's important to check the fit of the model, to see if the underlying assumptions are reasonable. One way to do this is to perform **posterior predictive checks**. This involves generating simulated data using the model that you built, and comparing that data to the observed data.\n",
    "\n",
    "One can choose a particular statistic to compare, such as tail probabilities or quartiles, but here it is useful to compare them graphically.\n",
    "\n",
    "We already have these simulations from our `sns.distplot` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(radon_samples, label='simulated')\n",
    "sns.distplot(hennepin_radon, label='observed')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior sensitivity\n",
    "\n",
    "It is also important to check the sensitivity of your choice of priors to the resulting inference. What if we had guessed completely different hyperparameters?\n",
    "\n",
    "Here's the same model, with drastically different (though still uninformative) priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Flat, HalfCauchy\n",
    "\n",
    "with Model() as prior_sensitivity:\n",
    "    \n",
    "    Î¼ = Flat('Î¼')\n",
    "    Ïƒ = HalfCauchy('Ïƒ', 5)\n",
    "    \n",
    "    dist = Normal('dist', mu=Î¼, sd=Ïƒ, observed=hennepin_radon)\n",
    "    \n",
    "    sensitivity_samples = fit(random_seed=RANDOM_SEED).sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior(sensitivity_samples, varnames=['Î¼'], ref_val=np.log(4), color='LightSeaGreen');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the original model for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior(samples, varnames=['Î¼'], ref_val=np.log(4), color='LightSeaGreen');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not much difference* gives us a degree of confidence that our results are good :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab #2: Spying on my girlfriend\n",
    "\n",
    "Ok, let's do some fun data science now. Help me spy on my girlfriend to make sure she does not swap me for a better model. Actually, i'll give you the data. You just do the data science to tell me she is still faithful to me, ok?\n",
    "\n",
    "Instead of variational inference, we are going to leverage Markov Chain Monte Carlo (MCMC)\n",
    "methods to model data. Running the Metropolis algorithm may crash your kernel if your laptop is not powerful enough. But is'a good example of probabilistic data science (and soooo useful to me), so let's take a closer look.\n",
    "\n",
    "If you agree, we'll try to model the rate at which my girlfriend sends and receives text messages, to better\n",
    "understand underlying dynamics. For example, it is well known that President Trump sends\n",
    "most of his Twitterstorms early in the morning. What can I infer from my girlfriend's cell phone activity,\n",
    "without actually looking at its content?\n",
    "\n",
    ">  You are given a series of daily text-message counts from my girlfriend. The data, plotted over time, appears in the chart below. I am curious to know if my girlfriend's text-messaging habits have changed over time, either gradually or suddenly. How to model this? \n",
    "\n",
    "Let's plot some data. First, download `mcmc.zip` from blackboard, unzip `txtdata.csv` and the two other images it contains a new folder called `data` in your Users folder. \n",
    "\n",
    "You can leverage linux commands either through `!` or *magic commands* which start with `%`. Use `%pwd` to check your current directory and `%cd /Enter/your/prefered/path/here/` to change it. It should be `Users\\<username>`. Then run the following script:\n",
    "\n",
    "```python\n",
    "figsize(12.5, 3.5)\n",
    "count_data = np.loadtxt(\"data/txtdata.csv\")\n",
    "n_count_data = len(count_data)\n",
    "plt.bar(np.arange(n_count_data), count_data, color=\"#348ABD\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"count of text-msgs received\")\n",
    "plt.title(\"Did my girlfriend's texting habits change over time?\")\n",
    "plt.xlim(0, n_count_data);\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12.5, 3.5)\n",
    "count_data = np.loadtxt(\"data/txtdata.csv\")\n",
    "n_count_data = len(count_data)\n",
    "plt.bar(np.arange(n_count_data), count_data, color=\"#348ABD\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"count of text-msgs received\")\n",
    "plt.title(\"Did Dino's girlfriend's texting activity change over time?\")\n",
    "plt.xlim(0, n_count_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start modeling this data (more exactly, the process underlying this data), see what you can figure out just by looking at the chart above. Would you say there was a change in behaviour during this time period? \n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/garfield.jpg\" width=200 />\n",
    "</center>\n",
    "\n",
    "How can we start to model this? A Poisson random variable is a more appropriate model for this type of *count* data, since count is discrete and count cannot go to infinity and is bounded by the most text messages received in one day. Denoting my girlfriend's day $i$'s text-message count by $C_i$, \n",
    "\n",
    "$$ C_i \\sim \\text{Poisson}(\\lambda)  $$\n",
    "\n",
    "We are not sure what the value of the $\\lambda$ parameter really is, however. Looking at the chart above, it appears that the rate might become higher later in the observation period, which is equivalent to saying that $\\lambda$ increases at some point during the observations (for discrete processes, expectation is equal to $\\lambda$; thus a higher value of $\\lambda$ assigns higher probability to larger outcomes. That is, there is a higher probability of many text messages having been sent on a given day).\n",
    "\n",
    "How can we represent this observation mathematically? Let's build a model. \n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/buildmodel.png\" width=400 />\n",
    "</center>\n",
    "\n",
    "Let's assume that on some day during the observation period (call it $\\tau$), the parameter $\\lambda$ suddenly jumps to a higher value, because my girlfriend has .. *met someone*.. Yikes! So we really have two $\\lambda$ parameters: one for the period before $\\tau$, and one for the rest of the observation period. In literature, a sudden transition like this is called a *switchpoint*; values of $\\lambda$ before $\\tau$ are called *anterior* distributions, and values after, *posterior*.\n",
    "\n",
    "$$\n",
    "\\lambda = \n",
    "\\begin{cases}\n",
    "\\lambda_1  & \\text{if } t \\lt \\tau \\cr\n",
    "\\lambda_2 & \\text{if } t \\ge \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "If, in reality, no sudden change occurred and indeed $\\lambda_1 = \\lambda_2$, then the $\\lambda$s posterior distributions should look about equal.\n",
    "\n",
    "We are interested in inferring the unknown $\\lambda$s. To use Bayesian inference, we need to assign prior probabilities to the different possible values of $\\lambda$. What would be good prior probability distributions for $\\lambda_1$ and $\\lambda_2$? Recall that $\\lambda$ can be any positive number. As we saw earlier, the *exponential* distribution provides a continuous density function for positive numbers, so it might be a good choice for modeling $\\lambda_i$. \n",
    "\n",
    "<span style=\"color:red\">Don't get confused.. we are still using the Poisson distribution for modeling the distribution of text messages received, but we will use the exponential distribution for modeling the $\\lambda$ of the Poisson distribution. Oh my!</span>\n",
    "\n",
    "Recall that the exponential distribution takes a parameter of its own, so we'll need to include that parameter in our model. Let's call that parameter $\\alpha$. Rememeber, model parameters are always denoted by *greek* letters.\n",
    "\n",
    "\\begin{align}\n",
    "&\\lambda_1 \\sim \\text{Exp}( \\alpha ) \\\\\\\n",
    "&\\lambda_2 \\sim \\text{Exp}( \\alpha )\n",
    "\\end{align}\n",
    "\n",
    "$\\alpha$ is called a *hyper-parameter* or *parent variable*. In literal terms, it is a parameter that influences other parameters. \n",
    "\n",
    "Our initial guess at $\\alpha$ should not influence the model too strongly, and we should have some flexibility in our choice.  A good hyperparameter rule of thumb is to set the exponential parameter equal to the inverse of the average of the count data. Since we're modeling $\\lambda$ using an exponential distribution, we can use the expected value identity shown earlier to get:\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{i=0}^N \\;C_i \\approx E\\;[\\; \\lambda \\; |\\; \\alpha ] = \\frac{1}{\\alpha}$$ \n",
    "\n",
    "A sound (er?) alternative would be to have *two* priors: one for each $\\lambda_i$. Creating two exponential distributions with different $\\alpha$ values reflects our prior belief that the rate changed at some point during the observations.\n",
    "\n",
    "What about $\\tau$? Because of the noisiness of the data, it's difficult to pick out a priori when $\\tau$ might have occurred. Instead, we can assign a *uniform prior belief* to every possible day. This is equivalent to saying\n",
    "\n",
    "\\begin{align}\n",
    "& \\tau \\sim \\text{DiscreteUniform(1, 70) }\\\\\\\\\n",
    "& \\Rightarrow P( \\tau = k ) = \\frac{1}{70}\n",
    "\\end{align}\n",
    "\n",
    "We now turn to `PyMC3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "with pm.Model() as model:\n",
    "    alpha = 1.0/count_data.mean()  # Recall count_data is the\n",
    "                                   # variable that holds our txt counts\n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", alpha)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", alpha)\n",
    "\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_count_data - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we create the PyMC3 variables corresponding to $\\lambda_1$ and $\\lambda_2$. We assign them to PyMC3's *stochastic variables*, so-called because they are treated by the back end as random number generators. And we hope we get no errors, because there is serious computation going on here, so please be patient. Then, run the following.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idx = np.arange(n_count_data) # Index\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a new function `lambda_`, but really we can think of it as a random variable: the random variable $\\lambda$ from above. The `switch()` function assigns `lambda_1` or `lambda_2` as the value of `lambda_`, depending on what side of `tau` we are on. The values of `lambda_` up until `tau` are `lambda_1` and the values afterwards are `lambda_2`.\n",
    "\n",
    "Note that because `lambda_1`, `lambda_2` and `tau` are random, `lambda_` will be random. We are **not** fixing any variables yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    observation = pm.Poisson(\"obs\", lambda_, observed=count_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `observation` combines our data, `count_data`, with our proposed data-generation scheme, given by the variable `lambda_`, through the `observed` keyword. \n",
    "\n",
    "The code below is a *learning* step. It's really a machine learning method. The machinery employed is called *Markov Chain Monte Carlo* (MCMC). This technique returns thousands of random variables from the posterior distributions of $\\lambda_1, \\lambda_2$ and $\\tau$. \n",
    "\n",
    "The [Metropolisâ€“Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)\n",
    "algorithm is a Markov chain Monte Carlo (MCMC) method for obtaining a sequence of random\n",
    "samples from a probability distribution for which direct sampling is difficult.\n",
    "\n",
    "The algorithm was named after Nicholas Metropolis, who was an author along with Edward Teller of\n",
    "the 1953 paper [Equation of State Calculations by Fast Computing Machines](https://bayes.wustl.edu/Manual/EquationOfState.pdf), which first proposed\n",
    "the algorithm for the case of symmetrical proposal distributions, and W. K. Hastings who extended it\n",
    "to the more general case in 1970. Nicholas Metropolis had already coined the term \"Monte Carlo\" in\n",
    "an earlier paper with Stanislav Ulam, was intimately familiar with the computational aspects of the\n",
    "method and also lead the group that designed and built the [MANIAC I](https://en.wikipedia.org/wiki/MANIAC_I) computer in 1952, which was used in the experiments. MANIAC 1 could be thought of as the first Data Science computer.\n",
    "\n",
    "We plot a histogram of the random variables to see what the posterior distributions look like. Below, we collect the samples (called *traces* in the MCMC literature) into histograms. \n",
    "\n",
    "Depending on the step size you pick below as parameters to `pm.sample`, this code could potentially crash your Jupyter kernel.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"http://currentsurroundings.com/content/random/calvin-hobbes/large/calvin_and_hobbes_067.jpg\" width = 150>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Metropolis-Hastings simulation\n",
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(4000, tune=1000, step=step, njobs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you crashed, you should have a yellow `connecting to kernel` or red `stopped` status bar at the top of your notebook. That means you are *hosed* and will not be able to execute any more cells. Oh well.. nice try.. go watch an episode of GoT and come back and.. replace your pm.sample() call with:\n",
    "```python\n",
    "trace = pm.sample(3000, tune=800, step=step, njobs = 1)\n",
    "```\n",
    "Some other things to try is to reduce 4000 and the `tune` parameter even more.. but then your algorithm might not converge, so find a point at which it works but does nto converge, and keep increasing the parameters untill Metroplois converges. Then carry on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1_samples = trace['lambda_1']\n",
    "lambda_2_samples = trace['lambda_2']\n",
    "tau_samples = trace['tau']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to plot the posterior distributions of our model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12.5, 10)\n",
    "#histogram of the samples:\n",
    "\n",
    "ax = plt.subplot(311)\n",
    "ax.set_autoscaley_on(False)\n",
    "\n",
    "plt.hist(lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=\"posterior of $\\lambda_1$\", color=\"#A60628\", normed=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(r\"\"\"Posterior distributions of the variables\n",
    "    $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel(\"$\\lambda_1$ value\")\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=\"posterior of $\\lambda_2$\", color=\"#7A68A6\", normed=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel(\"$\\lambda_2$ value\")\n",
    "\n",
    "plt.subplot(313)\n",
    "w = 1.0 / tau_samples.shape[0] * np.ones_like(tau_samples)\n",
    "plt.hist(tau_samples, bins=n_count_data, alpha=1,\n",
    "         label=r\"posterior of $\\tau$\",\n",
    "         color=\"#467821\", weights=w, rwidth=2.)\n",
    "plt.xticks(np.arange(n_count_data))\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim([0, .75])\n",
    "plt.xlim([35, len(count_data)-20])\n",
    "plt.xlabel(r\"$\\tau$ (in days)\")\n",
    "plt.ylabel(\"probability\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Recall that Bayesian methodology returns a *distribution*. Hence we now have distributions to describe the unknown $\\lambda$s and $\\tau$. What have we gained? Immediately, we can see the uncertainty in our estimates: the wider the distribution (the more choice of $\\lambda$), the less certain our posterior belief should be. But we can also see what the plausible values for the parameters are: $\\lambda_1$ should be around 18 and $\\lambda_2$ around 23. The posterior distributions of the two $\\lambda$s are clearly distinct, indicating that it is *indeed likely* that there was a change in my girlfriend's text-message behaviour.\n",
    "\n",
    "Notice also that the posterior distributions for the $\\lambda$s do not look like exponential distributions, even though our priors for these variables were exponential. In fact, the posterior distributions are not really of any form that we recognize from the original model. They look like normal distributions! It leads me to believe that I should have picked normal distributions for these priors. But if I do and get the same result, it;s ok! This is one of the benefits of taking a computational point of view. If we had instead done this analysis using mathematical approaches, we would have been stuck with an analytically intractable position. Our use of a computational approach makes us indifferent to mathematical tractability.\n",
    "\n",
    "Our analysis also returned a distribution for $\\tau$. Its posterior distribution looks a little different from the other two because it is a *discrete* random variable, so it doesn't assign probabilities to intervals. We can see that near day 45, there is a close to 50% chance that my girlfriend's texting behaviour changed! Had no change occurred, or had the change been gradual over time, the posterior distribution of $\\tau$ would have been more spread out, reflecting that many days were plausible candidates for $\\tau$. By contrast, in the actual results we see that only three or four days make any sense as potential transition points. \n",
    "\n",
    "Nice! (well, not very nice for me..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do I want to sample the posterior, anyways?\n",
    "\n",
    "We use posterior sampling to answer the following question: what is the expected number of texts at day $t, \\; 0 \\le t \\le 70$ ? Recall that the expected value of a Poisson variable is equal to its parameter $\\lambda$. Therefore, the question is equivalent to *what is the expected value of $\\lambda$ at time $t$*?\n",
    "\n",
    "In the code below, let $i$ index samples from the posterior distributions. Given a day $t$, we average over all possible $\\lambda_i$ for that day $t$, using $\\lambda_i = \\lambda_{1,i}$ if $t \\lt \\tau_i$ (that is, if the behaviour change has not yet occurred), else we use $\\lambda_i = \\lambda_{2,i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12.5, 5)\n",
    "# tau_samples, lambda_1_samples, lambda_2_samples contain\n",
    "# N samples from the corresponding posterior distribution\n",
    "N = tau_samples.shape[0]\n",
    "expected_texts_per_day = np.zeros(n_count_data)\n",
    "for day in range(0, n_count_data):\n",
    "    # ix is a bool index of all tau samples corresponding to\n",
    "    # the switchpoint occurring prior to value of 'day'\n",
    "    ix = day < tau_samples\n",
    "    # Each posterior sample corresponds to a value for tau.\n",
    "    # for each day, that value of tau indicates whether we're \"before\"\n",
    "    # (in the lambda1 \"regime\") or\n",
    "    #  \"after\" (in the lambda2 \"regime\") the switchpoint.\n",
    "    # by taking the posterior sample of lambda1/2 accordingly, we can average\n",
    "    # over all samples to get an expected value for lambda on that day.\n",
    "    # As explained, the \"message count\" random variable is Poisson distributed,\n",
    "    # and therefore lambda (the poisson parameter) is the expected value of\n",
    "    # \"message count\".\n",
    "    expected_texts_per_day[day] = (lambda_1_samples[ix].sum()\n",
    "                                   + lambda_2_samples[~ix].sum()) / N\n",
    "\n",
    "\n",
    "plt.plot(range(n_count_data), expected_texts_per_day, lw=4, color=\"#E24A33\",\n",
    "         label=\"expected number of text-messages received\")\n",
    "plt.xlim(0, n_count_data)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Expected # text-messages\")\n",
    "plt.title(\"Expected number of text-messages received by my girlfriend\")\n",
    "plt.ylim(0, 60)\n",
    "plt.bar(np.arange(len(count_data)), count_data, color=\"#348ABD\", alpha=0.65,\n",
    "        label=\"observed texts per day\")\n",
    "\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your analysis shows strong support for believing my girlfriend's behavior did change ($\\lambda_1$ would have been close in value to $\\lambda_2$ had this not been true), and that the change was sudden rather than gradual (as demonstrated by $\\tau$'s strongly peaked posterior distribution). We can only speculate what might have caused this: Perhaps a new relationship?! If i weren't a data scientist, I might have been fooled!\n",
    "\n",
    "It's interesting that you don't really have to scan for content to figure out dynamics involving content. You can just use probability and statistics and start counting to unearth events. This is how US government is running its domestic (and probably foreign, too) surveillance program. It does not need to spy on your cell phone conversations, but it most certainly catalogues the amount of texts and phone calls and can probably trace their origin and in some cases connect you to potentially shady characters, and *then start surveilling your messages and conversations*...\n",
    "\n",
    "And as far as i'm concerned..\n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/cry.png\" width=200 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Resources\n",
    "\n",
    "- Goodman, S. N. (1999). Toward evidence-based medical statistics. 1: The P value fallacy. Annals of Internal Medicine, 130(12), 995â€“1004. http://doi.org/10.7326/0003-4819-130-12-199906150-00008\n",
    "- Johnson, D. (1999). The insignificance of statistical significance testing. Journal of Wildlife Management, 63(3), 763â€“772.\n",
    "- Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis, Third Edition. CRC Press.\n",
    "-  Norvig, Peter. 2009. [The Unreasonable Effectiveness of Data](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf).\n",
    "- Salvatier, J, Wiecki TV, and Fonnesbeck C. (2016) Probabilistic programming in Python using PyMC3. *PeerJ Computer Science* 2:e55 <https://doi.org/10.7717/peerj-cs.55>\n",
    "- Cronin, Beau. \"Why Probabilistic Programming Matters.\" 24 Mar 2013. Google, Online Posting to Google . Web. 24 Mar. 2013. <https://plus.google.com/u/0/107971134877020469960/posts/KpeRdJKR6Z1>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
